{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75e625a",
   "metadata": {},
   "source": [
    " # Scraping Top Repositories for Topics on GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ff1e0c",
   "metadata": {},
   "source": [
    "#### Project Outline\n",
    "\n",
    "- We're going to scrape https://github.com/topics\n",
    "- We'll get a list of topics. For each topic, we'll get topic title, topic page URL and topic description\n",
    "- For each topic, we'll get the top 20 repositories in the topic from the topic page\n",
    "- For each repository, we'll grab the repo name, username, stars and repo URL\n",
    "- For each topic we'll create a CSV file in the following format:\n",
    "\n",
    "```\n",
    "Repo Name,Username,Stars,Repo URL\n",
    "three.js,mrdoob,69700,https://github.com/mrdoob/three.js\n",
    "libgdx,libgdx,18300,https://github.com/libgdx/libgdx\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0961507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c658cf",
   "metadata": {},
   "source": [
    "### Scrape the list of topics from Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b07ac1f",
   "metadata": {},
   "source": [
    "-use requests to download the page\n",
    "\n",
    "-user BS4 to parse and extract information\n",
    "\n",
    "-convert to a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4310a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_page():\n",
    "    # Define the URL for the GitHub topics page\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    \n",
    "    # Send a GET request to the topics URL\n",
    "    response = requests.get(topics_url)\n",
    "    \n",
    "    # Check if the response status code is not 200 (OK)\n",
    "    if response.status_code != 200:\n",
    "        # Raise an exception if the page failed to load\n",
    "        raise Exception('Failed to load page {}'.format(topics_url))\n",
    "    \n",
    "    # Parse the HTML content of the response using BeautifulSoup\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Return the parsed document\n",
    "    return doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83af6d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_topics_page()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffdd469",
   "metadata": {},
   "source": [
    "Let's create some helper functions to parse information from the page.\n",
    "\n",
    "To get topic titles, we can pick `p` tags with the `class` ...\n",
    "\n",
    "![](https://i.imgur.com/OnzIdyP.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd293faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(doc):\n",
    "    # Define the CSS class used for topic title paragraphs on the GitHub topics page\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    \n",
    "    # Find all <p> tags with the specified class in the provided document\n",
    "    topic_title_tags = doc.find_all('p', {'class': selection_class})\n",
    "    \n",
    "    # Initialize an empty list to store the extracted topic titles\n",
    "    topic_titles = []\n",
    "    \n",
    "    # Iterate through each tag found\n",
    "    for tag in topic_title_tags:\n",
    "        # Append the text content of each tag to the topic_titles list\n",
    "        topic_titles.append(tag.text)\n",
    "    \n",
    "    # Return the list of topic titles\n",
    "    return topic_titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "962c62d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `get_topic_titles` can be used to get the list of titles\n",
    "titles = get_topic_titles(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cef87bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49c4bea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3D', 'Ajax', 'Algorithm', 'Amp', 'Android']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85394f15",
   "metadata": {},
   "source": [
    "Similarly we have defined functions for descriptions and URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0b889f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_descs(doc):\n",
    "    # Define the CSS class used for topic description paragraphs on the GitHub topics page\n",
    "    desc_selector = 'f5 color-fg-muted mb-0 mt-1'\n",
    "    \n",
    "    # Find all <p> tags with the specified class in the provided document\n",
    "    topic_desc_tags = doc.find_all('p', {'class': desc_selector})\n",
    "    \n",
    "    # Initialize an empty list to store the extracted topic descriptions\n",
    "    topic_descs = []\n",
    "    \n",
    "    # Iterate through each tag found\n",
    "    for tag in topic_desc_tags:\n",
    "        # Append the stripped text content of each tag to the topic_descs list\n",
    "        topic_descs.append(tag.text.strip())\n",
    "    \n",
    "    # Return the list of topic descriptions\n",
    "    return topic_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2ec48f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = get_topic_descs(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e508181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f37eb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3D refers to the use of three-dimensional graphics, modeling, and animation in various industries.',\n",
       " 'Ajax is a technique for creating interactive web applications.',\n",
       " 'Algorithms are self-contained sequences that carry out a variety of tasks.',\n",
       " 'Amp is a non-blocking concurrency library for PHP.',\n",
       " 'Android is an operating system built by Google designed for mobile devices.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b159ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_urls(doc):\n",
    "    # Find all <a> tags with the specified class used for topic URLs on the GitHub topics page\n",
    "    topic_link_tags = doc.find_all('a', {'class': 'no-underline flex-1 d-flex flex-column'})\n",
    "    \n",
    "    # Initialize an empty list to store the full topic URLs\n",
    "    topic_urls = []\n",
    "    \n",
    "    # Base GitHub URL to be prefixed to relative topic URLs\n",
    "    base_url = 'https://github.com'\n",
    "    \n",
    "    # Iterate through each <a> tag found\n",
    "    for tag in topic_link_tags:\n",
    "        # Append the full URL by combining the base URL with the href attribute of the tag\n",
    "        topic_urls.append(base_url + tag['href'])\n",
    "    \n",
    "    # Return the list of full topic URLs\n",
    "    return topic_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9207b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = get_topic_urls(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4d74e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9f8f2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/topics/3d',\n",
       " 'https://github.com/topics/ajax',\n",
       " 'https://github.com/topics/algorithm',\n",
       " 'https://github.com/topics/amphp',\n",
       " 'https://github.com/topics/android']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ac95e",
   "metadata": {},
   "source": [
    "Let's put this all together into a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5a52a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics():\n",
    "    # Define the URL for the GitHub topics page\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    \n",
    "    # Send a GET request to the topics URL\n",
    "    response = requests.get(topics_url)\n",
    "    \n",
    "    # Check if the response status code is not 200 (OK)\n",
    "    if response.status_code != 200:\n",
    "        # Raise an exception if the page failed to load\n",
    "        raise Exception('Failed to load page {}'.format(topics_url))\n",
    "    \n",
    "    # Parse the HTML content of the response using BeautifulSoup\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Create a dictionary to store topic titles, descriptions, and URLs\n",
    "    topics_dict = {\n",
    "        'title': get_topic_titles(doc),        # Get the topic titles from the document\n",
    "        'description': get_topic_descs(doc),   # Get the topic descriptions from the document\n",
    "        'url': get_topic_urls(doc)              # Get the topic URLs from the document\n",
    "    }\n",
    "    \n",
    "    # Convert the topics dictionary into a DataFrame and return it\n",
    "    return pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "840a9350",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df = scrape_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cbb328c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D</td>\n",
       "      <td>3D refers to the use of three-dimensional grap...</td>\n",
       "      <td>https://github.com/topics/3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax is a technique for creating interactive w...</td>\n",
       "      <td>https://github.com/topics/ajax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algorithm</td>\n",
       "      <td>Algorithms are self-contained sequences that c...</td>\n",
       "      <td>https://github.com/topics/algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amp</td>\n",
       "      <td>Amp is a non-blocking concurrency library for ...</td>\n",
       "      <td>https://github.com/topics/amphp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Android</td>\n",
       "      <td>Android is an operating system built by Google...</td>\n",
       "      <td>https://github.com/topics/android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Angular</td>\n",
       "      <td>Angular is an open source web application plat...</td>\n",
       "      <td>https://github.com/topics/angular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ansible</td>\n",
       "      <td>Ansible is a simple and powerful automation en...</td>\n",
       "      <td>https://github.com/topics/ansible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>API</td>\n",
       "      <td>An API (Application Programming Interface) is ...</td>\n",
       "      <td>https://github.com/topics/api</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Arduino</td>\n",
       "      <td>Arduino is an open source platform for buildin...</td>\n",
       "      <td>https://github.com/topics/arduino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASP.NET</td>\n",
       "      <td>ASP.NET is a web framework for building modern...</td>\n",
       "      <td>https://github.com/topics/aspnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Awesome Lists</td>\n",
       "      <td>An awesome list is a list of awesome things cu...</td>\n",
       "      <td>https://github.com/topics/awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Amazon Web Services</td>\n",
       "      <td>Amazon Web Services provides on-demand cloud c...</td>\n",
       "      <td>https://github.com/topics/aws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Azure</td>\n",
       "      <td>Azure is a cloud computing service created by ...</td>\n",
       "      <td>https://github.com/topics/azure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Babel</td>\n",
       "      <td>Babel is a compiler for writing next generatio...</td>\n",
       "      <td>https://github.com/topics/babel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bash</td>\n",
       "      <td>Bash is a shell and command language interpret...</td>\n",
       "      <td>https://github.com/topics/bash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin is a cryptocurrency developed by Satos...</td>\n",
       "      <td>https://github.com/topics/bitcoin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bootstrap</td>\n",
       "      <td>Bootstrap is an HTML, CSS, and JavaScript fram...</td>\n",
       "      <td>https://github.com/topics/bootstrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bot</td>\n",
       "      <td>A bot is an application that runs automated ta...</td>\n",
       "      <td>https://github.com/topics/bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C</td>\n",
       "      <td>C is a general purpose programming language th...</td>\n",
       "      <td>https://github.com/topics/c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chrome</td>\n",
       "      <td>Chrome is a web browser from the tech company ...</td>\n",
       "      <td>https://github.com/topics/chrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chrome extension</td>\n",
       "      <td>Chrome extensions enable users to customize th...</td>\n",
       "      <td>https://github.com/topics/chrome-extension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Command-line interface</td>\n",
       "      <td>A CLI, or command-line interface, is a console...</td>\n",
       "      <td>https://github.com/topics/cli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Clojure</td>\n",
       "      <td>Clojure is a dynamic, general-purpose programm...</td>\n",
       "      <td>https://github.com/topics/clojure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Code quality</td>\n",
       "      <td>Automate your code review with style, quality,...</td>\n",
       "      <td>https://github.com/topics/code-quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Code review</td>\n",
       "      <td>Ensure your code meets quality standards and s...</td>\n",
       "      <td>https://github.com/topics/code-review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Compiler</td>\n",
       "      <td>Compilers are software that translate higher-l...</td>\n",
       "      <td>https://github.com/topics/compiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Continuous integration</td>\n",
       "      <td>Automatically build and test your code as you ...</td>\n",
       "      <td>https://github.com/topics/continuous-integration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>C++</td>\n",
       "      <td>C++ is a general purpose and object-oriented p...</td>\n",
       "      <td>https://github.com/topics/cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cryptocurrency</td>\n",
       "      <td>A cryptocurrency is a digital currency that us...</td>\n",
       "      <td>https://github.com/topics/cryptocurrency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Crystal</td>\n",
       "      <td>Crystal is a self-hosted, general purpose prog...</td>\n",
       "      <td>https://github.com/topics/crystal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                                        description  \\\n",
       "0                       3D  3D refers to the use of three-dimensional grap...   \n",
       "1                     Ajax  Ajax is a technique for creating interactive w...   \n",
       "2                Algorithm  Algorithms are self-contained sequences that c...   \n",
       "3                      Amp  Amp is a non-blocking concurrency library for ...   \n",
       "4                  Android  Android is an operating system built by Google...   \n",
       "5                  Angular  Angular is an open source web application plat...   \n",
       "6                  Ansible  Ansible is a simple and powerful automation en...   \n",
       "7                      API  An API (Application Programming Interface) is ...   \n",
       "8                  Arduino  Arduino is an open source platform for buildin...   \n",
       "9                  ASP.NET  ASP.NET is a web framework for building modern...   \n",
       "10           Awesome Lists  An awesome list is a list of awesome things cu...   \n",
       "11     Amazon Web Services  Amazon Web Services provides on-demand cloud c...   \n",
       "12                   Azure  Azure is a cloud computing service created by ...   \n",
       "13                   Babel  Babel is a compiler for writing next generatio...   \n",
       "14                    Bash  Bash is a shell and command language interpret...   \n",
       "15                 Bitcoin  Bitcoin is a cryptocurrency developed by Satos...   \n",
       "16               Bootstrap  Bootstrap is an HTML, CSS, and JavaScript fram...   \n",
       "17                     Bot  A bot is an application that runs automated ta...   \n",
       "18                       C  C is a general purpose programming language th...   \n",
       "19                  Chrome  Chrome is a web browser from the tech company ...   \n",
       "20        Chrome extension  Chrome extensions enable users to customize th...   \n",
       "21  Command-line interface  A CLI, or command-line interface, is a console...   \n",
       "22                 Clojure  Clojure is a dynamic, general-purpose programm...   \n",
       "23            Code quality  Automate your code review with style, quality,...   \n",
       "24             Code review  Ensure your code meets quality standards and s...   \n",
       "25                Compiler  Compilers are software that translate higher-l...   \n",
       "26  Continuous integration  Automatically build and test your code as you ...   \n",
       "27                     C++  C++ is a general purpose and object-oriented p...   \n",
       "28          Cryptocurrency  A cryptocurrency is a digital currency that us...   \n",
       "29                 Crystal  Crystal is a self-hosted, general purpose prog...   \n",
       "\n",
       "                                                 url  \n",
       "0                       https://github.com/topics/3d  \n",
       "1                     https://github.com/topics/ajax  \n",
       "2                https://github.com/topics/algorithm  \n",
       "3                    https://github.com/topics/amphp  \n",
       "4                  https://github.com/topics/android  \n",
       "5                  https://github.com/topics/angular  \n",
       "6                  https://github.com/topics/ansible  \n",
       "7                      https://github.com/topics/api  \n",
       "8                  https://github.com/topics/arduino  \n",
       "9                   https://github.com/topics/aspnet  \n",
       "10                 https://github.com/topics/awesome  \n",
       "11                     https://github.com/topics/aws  \n",
       "12                   https://github.com/topics/azure  \n",
       "13                   https://github.com/topics/babel  \n",
       "14                    https://github.com/topics/bash  \n",
       "15                 https://github.com/topics/bitcoin  \n",
       "16               https://github.com/topics/bootstrap  \n",
       "17                     https://github.com/topics/bot  \n",
       "18                       https://github.com/topics/c  \n",
       "19                  https://github.com/topics/chrome  \n",
       "20        https://github.com/topics/chrome-extension  \n",
       "21                     https://github.com/topics/cli  \n",
       "22                 https://github.com/topics/clojure  \n",
       "23            https://github.com/topics/code-quality  \n",
       "24             https://github.com/topics/code-review  \n",
       "25                https://github.com/topics/compiler  \n",
       "26  https://github.com/topics/continuous-integration  \n",
       "27                     https://github.com/topics/cpp  \n",
       "28          https://github.com/topics/cryptocurrency  \n",
       "29                 https://github.com/topics/crystal  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b296b0",
   "metadata": {},
   "source": [
    "## Get the top 20 repositories from a topic page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5f3dc686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    # Download the page from the given topic URL\n",
    "    response = requests.get(topic_url)\n",
    "    \n",
    "    # Check if the response is successful (status code 200)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    \n",
    "    # Parse the HTML content of the response using BeautifulSoup\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    return topic_doc\n",
    "\n",
    "def parse_star_count(stars_str):\n",
    "    # Remove leading and trailing whitespace from the stars string\n",
    "    stars_str = stars_str.strip()\n",
    "    \n",
    "    # Check if the string ends with 'k' indicating thousands\n",
    "    if stars_str[-1] == 'k':\n",
    "        # Convert 'k' value to an integer\n",
    "        return int(float(stars_str[:-1]) * 1000)\n",
    "    \n",
    "    # If it doesn't end with 'k', return the integer value directly\n",
    "    return int(stars_str)\n",
    "\n",
    "def get_repo_info(h3_tag, star_tag):\n",
    "    # Base URL for GitHub\n",
    "    base_url = 'https://github.com'\n",
    "    \n",
    "    # Extract the username and repository name from the h3 tag\n",
    "    a_tags = h3_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()  # Extract username\n",
    "    repo_name = a_tags[1].text.strip()  # Extract repository name\n",
    "    \n",
    "    # Extract the repository URL\n",
    "    repo_url = base_url + a_tags[1]['href']\n",
    "    \n",
    "    # Extract star count using the helper function\n",
    "    stars = parse_star_count(star_tag.text.strip())\n",
    "    \n",
    "    return username, repo_name, stars, repo_url\n",
    "\n",
    "def get_topic_repos(topic_doc):\n",
    "    # Define the class used to identify repository title tags\n",
    "    h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "    \n",
    "    # Get all h3 tags containing repository title, URL, and username\n",
    "    repo_tags = topic_doc.find_all('h3', {'class': h3_selection_class})\n",
    "    \n",
    "    # Get all star count tags\n",
    "    star_tags = topic_doc.find_all('span', {'class': 'Counter js-social-count'})\n",
    "    \n",
    "    # Initialize a dictionary to store repository information\n",
    "    topic_repos_dict = {'username': [], 'repo_name': [], 'stars': [], 'repo_url': []}\n",
    "\n",
    "    # Iterate through the repository tags to extract information\n",
    "    for i in range(len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i], star_tags[i])  # Get repo info\n",
    "        topic_repos_dict['username'].append(repo_info[0])      # Append username\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])     # Append repo name\n",
    "        topic_repos_dict['stars'].append(repo_info[2])         # Append star count\n",
    "        topic_repos_dict['repo_url'].append(repo_info[3])      # Append repo URL\n",
    "        \n",
    "    # Convert the dictionary to a DataFrame and return it\n",
    "    return pd.DataFrame(topic_repos_dict)\n",
    "\n",
    "def scrape_topic(topic_url, path):\n",
    "    # Check if the CSV file already exists\n",
    "    if os.path.exists(path):\n",
    "        print(\"The file {} already exists. Skipping...\".format(path))\n",
    "        return\n",
    "    \n",
    "    # Get repository data and convert to DataFrame\n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    \n",
    "    # Save the DataFrame to a CSV file at the specified path\n",
    "    topic_df.to_csv(path, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2939fc",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "- We have a funciton to get the list of topics\n",
    "- We have a function to create a CSV file for scraped repos from a topics page\n",
    "- Let's create a function to put them together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "77987691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(doc):\n",
    "    # Define the CSS class used for topic title paragraphs on the GitHub topics page\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    \n",
    "    # Find all <p> tags with the specified class in the provided document\n",
    "    topic_title_tags = doc.find_all('p', {'class': selection_class})\n",
    "    \n",
    "    # Initialize an empty list to store the extracted topic titles\n",
    "    topic_titles = []\n",
    "    \n",
    "    # Iterate through each tag found\n",
    "    for tag in topic_title_tags:\n",
    "        # Append the text content of each tag to the topic_titles list\n",
    "        topic_titles.append(tag.text)\n",
    "    \n",
    "    # Return the list of topic titles\n",
    "    return topic_titles\n",
    "\n",
    "def get_topic_descs(doc):\n",
    "    # Correct selector for descriptions\n",
    "    desc_selector = 'f5 color-fg-muted mb-0 mt-1'  # Updated class for description tags\n",
    "    \n",
    "    # Find all <p> tags with the specified class in the provided document\n",
    "    topic_desc_tags = doc.find_all('p', {'class': desc_selector})\n",
    "    \n",
    "    # Initialize an empty list to store the extracted topic descriptions\n",
    "    topic_descs = []\n",
    "    \n",
    "    # Iterate through each tag found\n",
    "    for tag in topic_desc_tags:\n",
    "        # Append the stripped text content of each tag to the topic_descs list\n",
    "        topic_descs.append(tag.text.strip())\n",
    "        \n",
    "    # Return the list of topic descriptions\n",
    "    return topic_descs\n",
    "\n",
    "def get_topic_urls(doc):\n",
    "    # Correct selector for the topic URLs\n",
    "    topic_link_tags = doc.find_all('a', {'class': 'no-underline flex-1 d-flex flex-column'})\n",
    "    \n",
    "    # Initialize an empty list to store the full topic URLs\n",
    "    topic_urls = []\n",
    "    \n",
    "    # Base URL for GitHub\n",
    "    base_url = 'https://github.com'\n",
    "    \n",
    "    # Iterate through each <a> tag found\n",
    "    for tag in topic_link_tags:\n",
    "        # Append the full URL by combining the base URL with the href attribute of the tag\n",
    "        topic_urls.append(base_url + tag['href'])\n",
    "    \n",
    "    # Return the list of full topic URLs\n",
    "    return topic_urls\n",
    "\n",
    "def scrape_topics():\n",
    "    # Define the URL for the GitHub topics page\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    \n",
    "    # Send a GET request to the topics URL\n",
    "    response = requests.get(topics_url)\n",
    "    \n",
    "    # Check if the response status code is not 200 (OK)\n",
    "    if response.status_code != 200:\n",
    "        # Raise an exception if the page failed to load\n",
    "        raise Exception('Failed to load page {}'.format(topics_url))\n",
    "    \n",
    "    # Parse the page using BeautifulSoup\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Get titles, descriptions, and URLs from the parsed document\n",
    "    titles = get_topic_titles(doc)\n",
    "    descs = get_topic_descs(doc)  # This should now work\n",
    "    urls = get_topic_urls(doc)\n",
    "    \n",
    "    # Print lengths for debugging purposes\n",
    "    print(f\"Titles: {len(titles)}, Descriptions: {len(descs)}, URLs: {len(urls)}\")\n",
    "    \n",
    "    # Ensure the lists have the same length\n",
    "    min_length = min(len(titles), len(descs), len(urls))\n",
    "    \n",
    "    # Trim each list to the minimum length to ensure they match\n",
    "    titles = titles[:min_length]\n",
    "    descs = descs[:min_length]\n",
    "    urls = urls[:min_length]\n",
    "    \n",
    "    # Create a dictionary to organize the topic data\n",
    "    topics_dict = {\n",
    "        'title': titles,\n",
    "        'description': descs,\n",
    "        'url': urls\n",
    "    }\n",
    "    \n",
    "    # Convert the topics dictionary into a DataFrame and return it\n",
    "    return pd.DataFrame(topics_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "50c948e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    # Print message indicating the start of topic scraping\n",
    "    print('Scraping list of topics')\n",
    "    \n",
    "    # Call the scrape_topics function to get the DataFrame of topics\n",
    "    topics_df = scrape_topics()\n",
    "    \n",
    "    # Create a 'data' directory if it doesn't exist to store CSV files\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    # Iterate through each row in the topics DataFrame\n",
    "    for index, row in topics_df.iterrows():\n",
    "        # Print message indicating which topic's top repositories are being scraped\n",
    "        print('Scraping top repositories for \"{}\"'.format(row['title']))\n",
    "        \n",
    "        # Call the scrape_topic function to scrape top repositories for the current topic\n",
    "        # Save the results as a CSV file named after the topic\n",
    "        scrape_topic(row['url'], 'data/{}.csv'.format(row['title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b74124",
   "metadata": {},
   "source": [
    "Let's run it to scrape the top repos for the all the topics on the first page of https://github.com/topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1cbd39f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping list of topics\n",
      "Titles: 30, Descriptions: 30, URLs: 30\n",
      "Scraping top repositories for \"3D\"\n",
      "The file data/3D.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Ajax\"\n",
      "The file data/Ajax.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Algorithm\"\n",
      "The file data/Algorithm.csv already exists. Skipping...\n",
      "Scraping top repositories for \"Amp\"\n",
      "Scraping top repositories for \"Android\"\n",
      "Scraping top repositories for \"Angular\"\n",
      "Scraping top repositories for \"Ansible\"\n",
      "Scraping top repositories for \"API\"\n",
      "Scraping top repositories for \"Arduino\"\n",
      "Scraping top repositories for \"ASP.NET\"\n",
      "Scraping top repositories for \"Awesome Lists\"\n",
      "Scraping top repositories for \"Amazon Web Services\"\n",
      "Scraping top repositories for \"Azure\"\n",
      "Scraping top repositories for \"Babel\"\n",
      "Scraping top repositories for \"Bash\"\n",
      "Scraping top repositories for \"Bitcoin\"\n",
      "Scraping top repositories for \"Bootstrap\"\n",
      "Scraping top repositories for \"Bot\"\n",
      "Scraping top repositories for \"C\"\n",
      "Scraping top repositories for \"Chrome\"\n",
      "Scraping top repositories for \"Chrome extension\"\n",
      "Scraping top repositories for \"Command-line interface\"\n",
      "Scraping top repositories for \"Clojure\"\n",
      "Scraping top repositories for \"Code quality\"\n",
      "Scraping top repositories for \"Code review\"\n",
      "Scraping top repositories for \"Compiler\"\n",
      "Scraping top repositories for \"Continuous integration\"\n",
      "Scraping top repositories for \"C++\"\n",
      "Scraping top repositories for \"Cryptocurrency\"\n",
      "Scraping top repositories for \"Crystal\"\n"
     ]
    }
   ],
   "source": [
    "scrape_topics_repos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
